{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "784b3449d6eb42e4b1bb7f2c394dbdb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8969fc8261784f8380173fcc4ca9c722",
              "IPY_MODEL_75dcdd37af954ce89f6bffffbdfbd318",
              "IPY_MODEL_a36537387a2449a5a2b263e32c50f20e"
            ],
            "layout": "IPY_MODEL_bf2211dab48244aa88b63446bb1fec40"
          }
        },
        "8969fc8261784f8380173fcc4ca9c722": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_517e95f83f9a4800811b0d2641d08a6c",
            "placeholder": "​",
            "style": "IPY_MODEL_9a24c9f1f2cf4d4a8d8bad71af4aca1e",
            "value": "Generating train split: "
          }
        },
        "75dcdd37af954ce89f6bffffbdfbd318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95811d7c5aa6437cae020cb5e72bdd4a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ddf5b3717e742288a4031dc47bf15d4",
            "value": 1
          }
        },
        "a36537387a2449a5a2b263e32c50f20e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a875d58f88b47e3b85c08e5b940eace",
            "placeholder": "​",
            "style": "IPY_MODEL_314ef5654de943338b4896400db9f32b",
            "value": " 293/0 [00:00&lt;00:00, 11711.58 examples/s]"
          }
        },
        "bf2211dab48244aa88b63446bb1fec40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "517e95f83f9a4800811b0d2641d08a6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a24c9f1f2cf4d4a8d8bad71af4aca1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95811d7c5aa6437cae020cb5e72bdd4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3ddf5b3717e742288a4031dc47bf15d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a875d58f88b47e3b85c08e5b940eace": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "314ef5654de943338b4896400db9f32b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32628bb255ce4feeb82df64767c06644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8882af728cdc45a5b758275cdc51edf6",
              "IPY_MODEL_6bc17761721e4e2698d47f4722af9d6e",
              "IPY_MODEL_08aa711076804371af8b0fb9e326fe96"
            ],
            "layout": "IPY_MODEL_9dd05276dd024c14a1a71796f8f13896"
          }
        },
        "8882af728cdc45a5b758275cdc51edf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6b4188a03764dbb9082a2dc29064627",
            "placeholder": "​",
            "style": "IPY_MODEL_0f25199633ab4883af4bdb56994cdf2a",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "6bc17761721e4e2698d47f4722af9d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dae0696891734e3a85e5b487f42694fb",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29cd4e1981f1481c946ef61b00ecf6f1",
            "value": 3
          }
        },
        "08aa711076804371af8b0fb9e326fe96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4991061726c3435f98e054e43c12844f",
            "placeholder": "​",
            "style": "IPY_MODEL_5565bc406db44c729c58ea04d2fa791b",
            "value": " 3/3 [00:07&lt;00:00,  2.48s/it]"
          }
        },
        "9dd05276dd024c14a1a71796f8f13896": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6b4188a03764dbb9082a2dc29064627": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f25199633ab4883af4bdb56994cdf2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dae0696891734e3a85e5b487f42694fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29cd4e1981f1481c946ef61b00ecf6f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4991061726c3435f98e054e43c12844f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5565bc406db44c729c58ea04d2fa791b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3b472e9170945af96cef21beb16aecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5856d20d1ffb45bebbafa481c2418281",
              "IPY_MODEL_2ba33a72fa8e447b951ae324ee391b72",
              "IPY_MODEL_4095f68926784b738510a6f7ad22ea62"
            ],
            "layout": "IPY_MODEL_2279d874b3424e6494ef18ee498e4cf2"
          }
        },
        "5856d20d1ffb45bebbafa481c2418281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5571165af0a545c4900f2f3a6c793ee3",
            "placeholder": "​",
            "style": "IPY_MODEL_e307842a1a92446484e1aaefa60872bd",
            "value": "Map: 100%"
          }
        },
        "2ba33a72fa8e447b951ae324ee391b72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad2e8304355b4cd784c1ffec57d2146e",
            "max": 293,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e2e6f32c39f43fa8174a78d3f33230a",
            "value": 293
          }
        },
        "4095f68926784b738510a6f7ad22ea62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_772dcf4189104f3e8b5e220fa2522675",
            "placeholder": "​",
            "style": "IPY_MODEL_5d4eac9e5ecc434bafcaee81f3b159c7",
            "value": " 293/293 [00:00&lt;00:00, 3885.70 examples/s]"
          }
        },
        "2279d874b3424e6494ef18ee498e4cf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5571165af0a545c4900f2f3a6c793ee3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e307842a1a92446484e1aaefa60872bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad2e8304355b4cd784c1ffec57d2146e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e2e6f32c39f43fa8174a78d3f33230a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "772dcf4189104f3e8b5e220fa2522675": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d4eac9e5ecc434bafcaee81f3b159c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdc70467a1084e50bb261bbbd2b1d835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5524a80127d47389b66cbbdd39100a5",
              "IPY_MODEL_0fd98ffe75cf4d1e9ce7b16c2218f981",
              "IPY_MODEL_b5ea82f138434b6ba2a2d8ab87fea27b"
            ],
            "layout": "IPY_MODEL_f78648a52a054db1973a7763c00f3fc3"
          }
        },
        "b5524a80127d47389b66cbbdd39100a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fa700f5603240d7a7904dacc4064bb5",
            "placeholder": "​",
            "style": "IPY_MODEL_b88fcc7e2d10489dbb626bd63c119f9d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "0fd98ffe75cf4d1e9ce7b16c2218f981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a167eb55cc83449c99725ad2800bce05",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ca3ea53dbc54c94aad19f8acf52b070",
            "value": 3
          }
        },
        "b5ea82f138434b6ba2a2d8ab87fea27b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f21a4d44f404436a9fa9073fd31b90c9",
            "placeholder": "​",
            "style": "IPY_MODEL_2f057390b69740b3aacc8621c164084e",
            "value": " 3/3 [00:08&lt;00:00,  2.77s/it]"
          }
        },
        "f78648a52a054db1973a7763c00f3fc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fa700f5603240d7a7904dacc4064bb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b88fcc7e2d10489dbb626bd63c119f9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a167eb55cc83449c99725ad2800bce05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ca3ea53dbc54c94aad19f8acf52b070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f21a4d44f404436a9fa9073fd31b90c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f057390b69740b3aacc8621c164084e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c4fc5ef79ed4e819b9f11c00bf83e75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6cdf95b0cbfe4887bb4024ce80fad29e",
              "IPY_MODEL_1752c22df4864256afd5753097fb77e0",
              "IPY_MODEL_c33e474deff2415fb8b9732c01af9a50"
            ],
            "layout": "IPY_MODEL_8e6e409a6a6c46c88b267a5f3508103f"
          }
        },
        "6cdf95b0cbfe4887bb4024ce80fad29e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc9792eb7f154885be408e4c11ca6ce7",
            "placeholder": "​",
            "style": "IPY_MODEL_5a6e04d6465d444e902590d47d1c3627",
            "value": "Upload 2 LFS files: 100%"
          }
        },
        "1752c22df4864256afd5753097fb77e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2080f54f45847989d2c4b0b158e61e9",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f6c7087babfc455bb4366124fa253d36",
            "value": 2
          }
        },
        "c33e474deff2415fb8b9732c01af9a50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a92307197ce465792a15b6e3b7de83c",
            "placeholder": "​",
            "style": "IPY_MODEL_fd8fa59c1a9f4b7c9049095719b60e24",
            "value": " 2/2 [04:06&lt;00:00, 246.25s/it]"
          }
        },
        "8e6e409a6a6c46c88b267a5f3508103f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc9792eb7f154885be408e4c11ca6ce7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a6e04d6465d444e902590d47d1c3627": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2080f54f45847989d2c4b0b158e61e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6c7087babfc455bb4366124fa253d36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a92307197ce465792a15b6e3b7de83c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd8fa59c1a9f4b7c9049095719b60e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a26be0cda4b5453f8c3abe2853101c95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_86ea32e7b8e8443e836e5faff5ee5f2b",
              "IPY_MODEL_307fca1d161f4b62801bf5e2eb504fe4",
              "IPY_MODEL_bff00fb43b0847d0ab4d8f541a63ba57"
            ],
            "layout": "IPY_MODEL_24071f8f218240ccadd62ad432f4fbcb"
          }
        },
        "86ea32e7b8e8443e836e5faff5ee5f2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c3ae458fb57420887e328ade55fe13b",
            "placeholder": "​",
            "style": "IPY_MODEL_bad8d2c465a84baf8bf6744db3ddd202",
            "value": "pytorch_model-00001-of-00002.bin: 100%"
          }
        },
        "307fca1d161f4b62801bf5e2eb504fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32d71a47906f4fa49a89bca71010e4ee",
            "max": 9976703909,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34d8cfa378984c938f926098be517223",
            "value": 9976703909
          }
        },
        "bff00fb43b0847d0ab4d8f541a63ba57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a145e8324f674266950dde9c450e9ef7",
            "placeholder": "​",
            "style": "IPY_MODEL_d57423411e794dafa5c9ba1dfbb08135",
            "value": " 9.98G/9.98G [04:05&lt;00:00, 44.8MB/s]"
          }
        },
        "24071f8f218240ccadd62ad432f4fbcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c3ae458fb57420887e328ade55fe13b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bad8d2c465a84baf8bf6744db3ddd202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32d71a47906f4fa49a89bca71010e4ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34d8cfa378984c938f926098be517223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a145e8324f674266950dde9c450e9ef7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d57423411e794dafa5c9ba1dfbb08135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03de228c22004aa5b52ae8abcd4ab0e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3ecfbe68c2b4dfeb7b343c04a3f50fb",
              "IPY_MODEL_d30eb48ed1614a9b99b1e225e412628e",
              "IPY_MODEL_cd9ca25145144450a00deb06f850cb27"
            ],
            "layout": "IPY_MODEL_f928f95b9ee54ff8a4ce6159392f50d2"
          }
        },
        "a3ecfbe68c2b4dfeb7b343c04a3f50fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7d811e50db649d3845292794a289182",
            "placeholder": "​",
            "style": "IPY_MODEL_8d777681646a44ceb814320717decb0a",
            "value": "pytorch_model-00002-of-00002.bin: 100%"
          }
        },
        "d30eb48ed1614a9b99b1e225e412628e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_761c8423c2284a8397ba3c60e3d9f1ca",
            "max": 3500382638,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c98007fa9a7544f8854412000611ed95",
            "value": 3500382638
          }
        },
        "cd9ca25145144450a00deb06f850cb27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87b8ee34e03e449798f4ca2287efdde4",
            "placeholder": "​",
            "style": "IPY_MODEL_34a78715444e42ada4840a4a5f1d4fe4",
            "value": " 3.50G/3.50G [01:33&lt;00:00, 33.3MB/s]"
          }
        },
        "f928f95b9ee54ff8a4ce6159392f50d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7d811e50db649d3845292794a289182": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d777681646a44ceb814320717decb0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "761c8423c2284a8397ba3c60e3d9f1ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c98007fa9a7544f8854412000611ed95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "87b8ee34e03e449798f4ca2287efdde4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34a78715444e42ada4840a4a5f1d4fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d3855ad164947b58fa23fe71614bb81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ff919aab90d477ca304091427aecf51",
              "IPY_MODEL_a747cc77839843dda7b7853a8f12a83c",
              "IPY_MODEL_81ed2b78046c403dac32eaeb1e8c2252"
            ],
            "layout": "IPY_MODEL_b42dde6570a340c7a4922501d02f078c"
          }
        },
        "0ff919aab90d477ca304091427aecf51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd88c9fc08a7427d95e77b4f35617be9",
            "placeholder": "​",
            "style": "IPY_MODEL_80b3d64ad1ec43a2a9d99621ccae6d8d",
            "value": "tokenizer.model: 100%"
          }
        },
        "a747cc77839843dda7b7853a8f12a83c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_761f5722b56441589a8f75a7e3d716b5",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d81e47f49ab4ca9a56697af255a47ca",
            "value": 499723
          }
        },
        "81ed2b78046c403dac32eaeb1e8c2252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2436fa7e8d4b4a34a986039ee0d896c8",
            "placeholder": "​",
            "style": "IPY_MODEL_b5d7606d0c4d426db621c09da8587afa",
            "value": " 500k/500k [00:00&lt;00:00, 159kB/s]"
          }
        },
        "b42dde6570a340c7a4922501d02f078c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd88c9fc08a7427d95e77b4f35617be9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80b3d64ad1ec43a2a9d99621ccae6d8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "761f5722b56441589a8f75a7e3d716b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d81e47f49ab4ca9a56697af255a47ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2436fa7e8d4b4a34a986039ee0d896c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5d7606d0c4d426db621c09da8587afa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13fb75b64c284eb98e52a87456f027f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72f146f0531c4bbdb0b1b13e975b2149",
              "IPY_MODEL_afecdc5045a54151b344b888092e449b",
              "IPY_MODEL_d5ddcc57665440d4b16033b6295bc2dc"
            ],
            "layout": "IPY_MODEL_5d83550acec341a7ac69a651cb739b06"
          }
        },
        "72f146f0531c4bbdb0b1b13e975b2149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60930f34cc2643df8ef4e51640b15f6c",
            "placeholder": "​",
            "style": "IPY_MODEL_c20683e2f15e489db86c4051c6cf71a1",
            "value": "granite-7b-lab-xbcfinetuned-q8_0-gguf.gguf: 100%"
          }
        },
        "afecdc5045a54151b344b888092e449b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10b18632b34f4dda868b2492d5b9a097",
            "max": 7161160064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c941c71c0634baa8610f9a89b70e8dc",
            "value": 7161160064
          }
        },
        "d5ddcc57665440d4b16033b6295bc2dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a84198f1c7074dbe8cb72d106f8143b7",
            "placeholder": "​",
            "style": "IPY_MODEL_e60219c1523c4d7bb5d865bf8e9d168e",
            "value": " 7.16G/7.16G [03:02&lt;00:00, 41.9MB/s]"
          }
        },
        "5d83550acec341a7ac69a651cb739b06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60930f34cc2643df8ef4e51640b15f6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c20683e2f15e489db86c4051c6cf71a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10b18632b34f4dda868b2492d5b9a097": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c941c71c0634baa8610f9a89b70e8dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a84198f1c7074dbe8cb72d106f8143b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e60219c1523c4d7bb5d865bf8e9d168e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xuliucool/LLM-and-AppModernization/blob/main/Fine-Tuning/XBC_Fine_tune_Llama_2_in_Google_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tune Llama 2 for XBC Bank POC in Google Colab\n",
        "> 🗣️ XBC Bank Large Language Model Fine tuning\n",
        "\n",
        "❤️ Extended by Ahilan Ponnusamy from the notebook referenced below\n",
        " Created by [@maximelabonne](https://twitter.com/maximelabonne) as explained in this [Blog](https://towardsdatascience.com/fine-tune-your-own-llama-2-model-in-a-colab-notebook-df9823a04a32)\n",
        "\n",
        "This notebook runs on a T4 GPU. (Last update: 23 Dec 2023)\n"
      ],
      "metadata": {
        "id": "OSHlAbqzDFDq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GLXwJqbjtPho",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edbcf3ef-774c-4e4f-b1de-0fcc8fe351bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m204.8/244.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    HfArgumentParser,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        ")\n",
        "from peft import LoraConfig, PeftModel\n",
        "from trl import SFTTrainer"
      ],
      "metadata": {
        "id": "nAMzy_0FtaUZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The model that you want to train from the Hugging Face hub\n",
        "#model_name = \"NousResearch/Llama-2-7b-chat-hf\"\n",
        "model_name = \"instructlab/granite-7b-lab\"\n",
        "\n",
        "# The instruction dataset to use\n",
        "#dataset_name = \"mlabonne/guanaco-llama2-1k\"\n",
        "#dataset_name = \"AhilanPonnusamy/data\"\n",
        "\n",
        "file_dict = {\n",
        "  \"train\" : \"/content/data/xbc_train.csv\",\n",
        "}\n",
        "\n",
        "# Fine-tuned model name\n",
        "#new_model = \"llama-2-7b-xbcfinetuned\"\n",
        "new_model = \"granite-7b-lab-xbcft\"\n",
        "\n",
        "################################################################################\n",
        "# QLoRA parameters\n",
        "################################################################################\n",
        "\n",
        "# LoRA attention dimension\n",
        "lora_r = 64\n",
        "\n",
        "# Alpha parameter for LoRA scaling\n",
        "lora_alpha = 16\n",
        "\n",
        "# Dropout probability for LoRA layers\n",
        "lora_dropout = 0.1\n",
        "\n",
        "################################################################################\n",
        "# bitsandbytes parameters\n",
        "################################################################################\n",
        "\n",
        "# Activate 4-bit precision base model loading\n",
        "use_4bit = True\n",
        "\n",
        "# Compute dtype for 4-bit base models\n",
        "bnb_4bit_compute_dtype = \"float16\"\n",
        "\n",
        "# Quantization type (fp4 or nf4)\n",
        "bnb_4bit_quant_type = \"nf4\"\n",
        "\n",
        "# Activate nested quantization for 4-bit base models (double quantization)\n",
        "use_nested_quant = False\n",
        "\n",
        "################################################################################\n",
        "# TrainingArguments parameters\n",
        "################################################################################\n",
        "\n",
        "# Output directory where the model predictions and checkpoints will be stored\n",
        "output_dir = \"./results\"\n",
        "\n",
        "# Number of training epochs\n",
        "num_train_epochs = 3\n",
        "\n",
        "# Enable fp16/bf16 training (set bf16 to True with an A100)\n",
        "fp16 = False\n",
        "bf16 = False\n",
        "\n",
        "# Batch size per GPU for training\n",
        "per_device_train_batch_size = 4\n",
        "\n",
        "# Batch size per GPU for evaluation\n",
        "per_device_eval_batch_size = 4\n",
        "\n",
        "# Number of update steps to accumulate the gradients for\n",
        "gradient_accumulation_steps = 1\n",
        "\n",
        "# Enable gradient checkpointing\n",
        "gradient_checkpointing = True\n",
        "\n",
        "# Maximum gradient normal (gradient clipping)\n",
        "max_grad_norm = 0.3\n",
        "\n",
        "# Initial learning rate (AdamW optimizer)\n",
        "learning_rate = 2e-4\n",
        "\n",
        "# Weight decay to apply to all layers except bias/LayerNorm weights\n",
        "weight_decay = 0.001\n",
        "\n",
        "# Optimizer to use\n",
        "optim = \"paged_adamw_32bit\"\n",
        "\n",
        "# Learning rate schedule\n",
        "lr_scheduler_type = \"cosine\"\n",
        "\n",
        "# Number of training steps (overrides num_train_epochs)\n",
        "max_steps = -1\n",
        "\n",
        "# Ratio of steps for a linear warmup (from 0 to learning rate)\n",
        "warmup_ratio = 0.03\n",
        "\n",
        "# Group sequences into batches with same length\n",
        "# Saves memory and speeds up training considerably\n",
        "group_by_length = True\n",
        "\n",
        "# Save checkpoint every X updates steps\n",
        "save_steps = 0\n",
        "\n",
        "# Log every X updates steps\n",
        "logging_steps = 25\n",
        "\n",
        "################################################################################\n",
        "# SFT parameters\n",
        "################################################################################\n",
        "\n",
        "# Maximum sequence length to use\n",
        "#max_seq_length = None\n",
        "max_seq_length = 10240\n",
        "\n",
        "# Pack multiple short examples in the same input sequence to increase efficiency\n",
        "packing = False\n",
        "\n",
        "# Load the entire model on the GPU 0\n",
        "device_map = {\"\": 0}"
      ],
      "metadata": {
        "id": "ib_We3NLtj2E"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset (you can process it here)\n",
        "#dataset = load_dataset(dataset_name, split=\"train\")\n",
        "#load xbc training dataset\n",
        "dataset = load_dataset(\n",
        "  'csv',\n",
        "  data_files=file_dict\n",
        ")\n",
        "\n",
        "# Load tokenizer and model with QLoRA configuration\n",
        "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=use_4bit,\n",
        "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        "    bnb_4bit_use_double_quant=use_nested_quant,\n",
        ")\n",
        "\n",
        "# Check GPU compatibility with bfloat16\n",
        "if compute_dtype == torch.float16 and use_4bit:\n",
        "    major, _ = torch.cuda.get_device_capability()\n",
        "    if major >= 8:\n",
        "        print(\"=\" * 80)\n",
        "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "# Load base model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=device_map\n",
        ")\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1\n",
        "\n",
        "# Load LLaMA tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\" # Fix weird overflow issue with fp16 training\n",
        "\n",
        "# Load LoRA configuration\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    r=lora_r,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "# Set training parameters\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    optim=optim,\n",
        "    save_steps=save_steps,\n",
        "    logging_steps=logging_steps,\n",
        "    learning_rate=learning_rate,\n",
        "    weight_decay=weight_decay,\n",
        "    fp16=fp16,\n",
        "    bf16=bf16,\n",
        "    max_grad_norm=max_grad_norm,\n",
        "    max_steps=max_steps,\n",
        "    warmup_ratio=warmup_ratio,\n",
        "    group_by_length=group_by_length,\n",
        "    lr_scheduler_type=lr_scheduler_type,\n",
        "    report_to=\"tensorboard\"\n",
        ")\n",
        "\n",
        "# Set supervised fine-tuning parameters\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing=packing,\n",
        ")\n",
        "\n",
        "# Train model\n",
        "trainer.train()\n",
        "\n",
        "# Save trained model\n",
        "trainer.model.save_pretrained(new_model)"
      ],
      "metadata": {
        "id": "OJXpOgBFuSrc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657,
          "referenced_widgets": [
            "784b3449d6eb42e4b1bb7f2c394dbdb3",
            "8969fc8261784f8380173fcc4ca9c722",
            "75dcdd37af954ce89f6bffffbdfbd318",
            "a36537387a2449a5a2b263e32c50f20e",
            "bf2211dab48244aa88b63446bb1fec40",
            "517e95f83f9a4800811b0d2641d08a6c",
            "9a24c9f1f2cf4d4a8d8bad71af4aca1e",
            "95811d7c5aa6437cae020cb5e72bdd4a",
            "3ddf5b3717e742288a4031dc47bf15d4",
            "3a875d58f88b47e3b85c08e5b940eace",
            "314ef5654de943338b4896400db9f32b",
            "32628bb255ce4feeb82df64767c06644",
            "8882af728cdc45a5b758275cdc51edf6",
            "6bc17761721e4e2698d47f4722af9d6e",
            "08aa711076804371af8b0fb9e326fe96",
            "9dd05276dd024c14a1a71796f8f13896",
            "e6b4188a03764dbb9082a2dc29064627",
            "0f25199633ab4883af4bdb56994cdf2a",
            "dae0696891734e3a85e5b487f42694fb",
            "29cd4e1981f1481c946ef61b00ecf6f1",
            "4991061726c3435f98e054e43c12844f",
            "5565bc406db44c729c58ea04d2fa791b",
            "d3b472e9170945af96cef21beb16aecd",
            "5856d20d1ffb45bebbafa481c2418281",
            "2ba33a72fa8e447b951ae324ee391b72",
            "4095f68926784b738510a6f7ad22ea62",
            "2279d874b3424e6494ef18ee498e4cf2",
            "5571165af0a545c4900f2f3a6c793ee3",
            "e307842a1a92446484e1aaefa60872bd",
            "ad2e8304355b4cd784c1ffec57d2146e",
            "2e2e6f32c39f43fa8174a78d3f33230a",
            "772dcf4189104f3e8b5e220fa2522675",
            "5d4eac9e5ecc434bafcaee81f3b159c7"
          ]
        },
        "outputId": "772a264e-3c58-4691-d26d-e4b1af0204d1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "784b3449d6eb42e4b1bb7f2c394dbdb3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "Your GPU supports bfloat16: accelerate training with bf16=True\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32628bb255ce4feeb82df64767c06644"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LlamaForCausalLM were not initialized from the model checkpoint at instructlab/granite-7b-lab and are newly initialized: ['model.layers.20.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.26.self_attn.rotary_emb.inv_freq', 'model.layers.23.self_attn.rotary_emb.inv_freq', 'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.28.self_attn.rotary_emb.inv_freq', 'model.layers.18.self_attn.rotary_emb.inv_freq', 'model.layers.31.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.24.self_attn.rotary_emb.inv_freq', 'model.layers.15.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.25.self_attn.rotary_emb.inv_freq', 'model.layers.14.self_attn.rotary_emb.inv_freq', 'model.layers.29.self_attn.rotary_emb.inv_freq', 'model.layers.27.self_attn.rotary_emb.inv_freq', 'model.layers.12.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.13.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.17.self_attn.rotary_emb.inv_freq', 'model.layers.30.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.22.self_attn.rotary_emb.inv_freq', 'model.layers.19.self_attn.rotary_emb.inv_freq', 'model.layers.21.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.16.self_attn.rotary_emb.inv_freq', 'model.layers.10.self_attn.rotary_emb.inv_freq']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/293 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3b472e9170945af96cef21beb16aecd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='222' max='222' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [222/222 01:54, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>2.192700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.494100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.454200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.435800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>0.329500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.375600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>0.338800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.284800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir results/runs"
      ],
      "metadata": {
        "id": "crj9svNe4hU5"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignore warnings\n",
        "logging.set_verbosity(logging.CRITICAL)\n",
        "\n",
        "# Run text generation pipeline with our next model\n",
        "prompt = \"can you transfer $50 to joseph?\"\n",
        "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\n",
        "result = pipe(f\"<s>[INST] {prompt} [/INST]\")\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "frlSLPin4IJ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cd70a5d-0b98-4f35-8871-9af769d521c1"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] can you transfer $50 to joseph? [/INST] Your transfer of $50 to Joseph was completed successfully. Your current balance is $50\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Empty VRAM\n",
        "del model\n",
        "del pipe\n",
        "del trainer\n",
        "import gc\n",
        "gc.collect()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkQCviG0Zta-",
        "outputId": "916ad381-bd6f-4da7-8838-eb3f2f4d6d07"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20933"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload model in FP16 and merge it with LoRA weights\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    low_cpu_mem_usage=True,\n",
        "    return_dict=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=device_map,\n",
        ")\n",
        "model = PeftModel.from_pretrained(base_model, new_model)\n",
        "model = model.merge_and_unload()\n",
        "\n",
        "# Reload tokenizer to save it\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ],
      "metadata": {
        "id": "QQn30cRtAZ-P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "bdc70467a1084e50bb261bbbd2b1d835",
            "b5524a80127d47389b66cbbdd39100a5",
            "0fd98ffe75cf4d1e9ce7b16c2218f981",
            "b5ea82f138434b6ba2a2d8ab87fea27b",
            "f78648a52a054db1973a7763c00f3fc3",
            "6fa700f5603240d7a7904dacc4064bb5",
            "b88fcc7e2d10489dbb626bd63c119f9d",
            "a167eb55cc83449c99725ad2800bce05",
            "6ca3ea53dbc54c94aad19f8acf52b070",
            "f21a4d44f404436a9fa9073fd31b90c9",
            "2f057390b69740b3aacc8621c164084e"
          ]
        },
        "outputId": "0655d291-620a-4f88-d941-e62d83e6ea6d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bdc70467a1084e50bb261bbbd2b1d835"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Default title text\n",
        "variable_name = \"\" # @param {type:\"string\"}\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "!huggingface-cli login\n",
        "\n",
        "model.push_to_hub(new_model, use_temp_dir=False)\n",
        "tokenizer.push_to_hub(new_model, use_temp_dir=False)"
      ],
      "metadata": {
        "id": "x-xPb-_qB0dz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470,
          "referenced_widgets": [
            "8c4fc5ef79ed4e819b9f11c00bf83e75",
            "6cdf95b0cbfe4887bb4024ce80fad29e",
            "1752c22df4864256afd5753097fb77e0",
            "c33e474deff2415fb8b9732c01af9a50",
            "8e6e409a6a6c46c88b267a5f3508103f",
            "bc9792eb7f154885be408e4c11ca6ce7",
            "5a6e04d6465d444e902590d47d1c3627",
            "a2080f54f45847989d2c4b0b158e61e9",
            "f6c7087babfc455bb4366124fa253d36",
            "9a92307197ce465792a15b6e3b7de83c",
            "fd8fa59c1a9f4b7c9049095719b60e24",
            "a26be0cda4b5453f8c3abe2853101c95",
            "86ea32e7b8e8443e836e5faff5ee5f2b",
            "307fca1d161f4b62801bf5e2eb504fe4",
            "bff00fb43b0847d0ab4d8f541a63ba57",
            "24071f8f218240ccadd62ad432f4fbcb",
            "7c3ae458fb57420887e328ade55fe13b",
            "bad8d2c465a84baf8bf6744db3ddd202",
            "32d71a47906f4fa49a89bca71010e4ee",
            "34d8cfa378984c938f926098be517223",
            "a145e8324f674266950dde9c450e9ef7",
            "d57423411e794dafa5c9ba1dfbb08135",
            "03de228c22004aa5b52ae8abcd4ab0e9",
            "a3ecfbe68c2b4dfeb7b343c04a3f50fb",
            "d30eb48ed1614a9b99b1e225e412628e",
            "cd9ca25145144450a00deb06f850cb27",
            "f928f95b9ee54ff8a4ce6159392f50d2",
            "d7d811e50db649d3845292794a289182",
            "8d777681646a44ceb814320717decb0a",
            "761c8423c2284a8397ba3c60e3d9f1ca",
            "c98007fa9a7544f8854412000611ed95",
            "87b8ee34e03e449798f4ca2287efdde4",
            "34a78715444e42ada4840a4a5f1d4fe4",
            "2d3855ad164947b58fa23fe71614bb81",
            "0ff919aab90d477ca304091427aecf51",
            "a747cc77839843dda7b7853a8f12a83c",
            "81ed2b78046c403dac32eaeb1e8c2252",
            "b42dde6570a340c7a4922501d02f078c",
            "cd88c9fc08a7427d95e77b4f35617be9",
            "80b3d64ad1ec43a2a9d99621ccae6d8d",
            "761f5722b56441589a8f75a7e3d716b5",
            "2d81e47f49ab4ca9a56697af255a47ca",
            "2436fa7e8d4b4a34a986039ee0d896c8",
            "b5d7606d0c4d426db621c09da8587afa"
          ]
        },
        "outputId": "9956bd8c-6894-4139-918f-3ec682513704"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c4fc5ef79ed4e819b9f11c00bf83e75"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a26be0cda4b5453f8c3abe2853101c95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03de228c22004aa5b52ae8abcd4ab0e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d3855ad164947b58fa23fe71614bb81"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/Samlxf/granite-7b-lab-xbcft/commit/a347bb5c45d900f3e94e3aab1fea13f43752edae', commit_message='Upload tokenizer', commit_description='', oid='a347bb5c45d900f3e94e3aab1fea13f43752edae', pr_url=None, pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "!git clone https://github.com/ggerganov/llama.cpp\n",
        "%cd llama.cpp\n",
        "#!make\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "6TFFZSGGtKJc",
        "outputId": "b78d0273-49ff-408f-a7a3-c38d9186c92a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llama.cpp'...\n",
            "remote: Enumerating objects: 25653, done.\u001b[K\n",
            "remote: Counting objects: 100% (9320/9320), done.\u001b[K\n",
            "remote: Compressing objects: 100% (542/542), done.\u001b[K\n",
            "remote: Total 25653 (delta 9039), reused 8840 (delta 8778), pack-reused 16333\u001b[K\n",
            "Receiving objects: 100% (25653/25653), 46.90 MiB | 25.41 MiB/s, done.\n",
            "Resolving deltas: 100% (18250/18250), done.\n",
            "/content/llama.cpp\n",
            "Collecting numpy~=1.24.4 (from -r ./requirements/requirements-convert.txt (line 1))\n",
            "  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece~=0.2.0 (from -r ./requirements/requirements-convert.txt (line 2))\n",
            "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers<5.0.0,>=4.40.1 (from -r ./requirements/requirements-convert.txt (line 3))\n",
            "  Downloading transformers-4.41.1-py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gguf>=0.1.0 (from -r ./requirements/requirements-convert.txt (line 4))\n",
            "  Downloading gguf-0.6.0-py3-none-any.whl (23 kB)\n",
            "Collecting protobuf<5.0.0,>=4.21.0 (from -r ./requirements/requirements-convert.txt (line 5))\n",
            "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch~=2.1.1 (from -r ./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.40.1->-r ./requirements/requirements-convert.txt (line 3)) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.40.1->-r ./requirements/requirements-convert.txt (line 3)) (0.23.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.40.1->-r ./requirements/requirements-convert.txt (line 3)) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.40.1->-r ./requirements/requirements-convert.txt (line 3)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.40.1->-r ./requirements/requirements-convert.txt (line 3)) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.40.1->-r ./requirements/requirements-convert.txt (line 3)) (2.31.0)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers<5.0.0,>=4.40.1->-r ./requirements/requirements-convert.txt (line 3))\n",
            "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.40.1->-r ./requirements/requirements-convert.txt (line 3)) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.40.1->-r ./requirements/requirements-convert.txt (line 3)) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r ./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r ./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r ./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r ./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r ./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r ./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r ./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r ./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r ./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r ./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r ./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r ./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r ./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r ./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (12.1.0.106)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from torch~=2.1.1->-r ./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r ./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (12.1.105)\n",
            "Collecting triton==2.1.0 (from torch~=2.1.1->-r ./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch~=2.1.1->-r ./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch~=2.1.1->-r ./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.40.1->-r ./requirements/requirements-convert.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.40.1->-r ./requirements/requirements-convert.txt (line 3)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.40.1->-r ./requirements/requirements-convert.txt (line 3)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.40.1->-r ./requirements/requirements-convert.txt (line 3)) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch~=2.1.1->-r ./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (1.3.0)\n",
            "Installing collected packages: sentencepiece, triton, protobuf, nvidia-nccl-cu12, numpy, gguf, torch, tokenizers, transformers\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.1.99\n",
            "    Uninstalling sentencepiece-0.1.99:\n",
            "      Successfully uninstalled sentencepiece-0.1.99\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.3.0\n",
            "    Uninstalling triton-2.3.0:\n",
            "      Successfully uninstalled triton-2.3.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.20.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.20.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.20.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.0+cu121\n",
            "    Uninstalling torch-2.3.0+cu121:\n",
            "      Successfully uninstalled torch-2.3.0+cu121\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.13.3\n",
            "    Uninstalling tokenizers-0.13.3:\n",
            "      Successfully uninstalled tokenizers-0.13.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.31.0\n",
            "    Uninstalling transformers-4.31.0:\n",
            "      Successfully uninstalled transformers-4.31.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.3 which is incompatible.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchvision 0.18.0+cu121 requires torch==2.3.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gguf-0.6.0 numpy-1.24.4 nvidia-nccl-cu12-2.18.1 protobuf-4.25.3 sentencepiece-0.2.0 tokenizers-0.19.1 torch-2.1.2 transformers-4.41.1 triton-2.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "sentencepiece",
                  "torch",
                  "torchgen",
                  "transformers",
                  "triton"
                ]
              },
              "id": "e10eab5ed9fd48e8879b4b340ec728d4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/ggerganov/llama.cpp.git\n",
        "#%cd llama.cpp\n",
        "#!make\n",
        "#!pip install -r requirements.txt\n",
        "!python convert.py /content/granite-7b-lab-xbcft \\\n",
        "    --outfile granite-7b-lab-xbcfinetuned-q8_0-gguf.gguf \\\n",
        "    --outtype q8_0 \\\n",
        "    --pad-vocab\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vhV6g97y6ew",
        "outputId": "d2c23a78-e81e-4a8e-c1be-85c7dd59ffa1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:convert:Loading model file /content/granite-7b-lab-xbcft/pytorch_model-00001-of-00002.bin\n",
            "INFO:convert:Loading model file /content/granite-7b-lab-xbcft/pytorch_model-00001-of-00002.bin\n",
            "INFO:convert:Loading model file /content/granite-7b-lab-xbcft/pytorch_model-00002-of-00002.bin\n",
            "INFO:convert:model parameters count : 6738483200 (7B)\n",
            "INFO:convert:params = Params(n_vocab=32008, n_embd=4096, n_layer=32, n_ctx=2048, n_ff=11008, n_head=32, n_head_kv=32, n_experts=None, n_experts_used=None, f_norm_eps=1e-05, rope_scaling_type=None, f_rope_freq_base=10000.0, f_rope_scale=None, n_orig_ctx=None, rope_finetuned=None, ftype=<GGMLFileType.MostlyQ8_0: 7>, path_model=PosixPath('/content/granite-7b-lab-xbcft'))\n",
            "INFO:convert:Loaded vocab file PosixPath('/content/granite-7b-lab-xbcft/tokenizer.model'), type 'spm'\n",
            "INFO:convert:Vocab info: <SentencePieceVocab with 32000 base tokens and 5 added tokens>\n",
            "INFO:convert:Special vocab info: <SpecialVocab with 0 merges, special tokens {'bos': 1, 'eos': 32000, 'unk': 0, 'pad': 32001}, add special tokens unset>\n",
            "INFO:convert:Writing granite-7b-lab-xbcfinetuned-q8_0-gguf.gguf, format 7\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:gguf.vocab:Setting special token type bos to 1\n",
            "INFO:gguf.vocab:Setting special token type eos to 32000\n",
            "INFO:gguf.vocab:Setting special token type unk to 0\n",
            "INFO:gguf.vocab:Setting special token type pad to 32001\n",
            "INFO:gguf.vocab:Setting chat_template to {% for message in messages %}{% if message['role'] == 'system' %}{{'<|system|>'+ '\n",
            "' + message['content'] + '\n",
            "'}}{% elif message['role'] == 'user' %}{{'<|user|>' + '\n",
            "' + message['content'] + '\n",
            "'}}{% elif message['role'] == 'assistant' %}{{'<|assistant|>' + '\n",
            "' + message['content'] + '<|endoftext|>' + ('' if loop.last else '\n",
            "')}}{% endif %}{% endfor %}\n",
            "/content/llama.cpp/convert.py:106: RuntimeWarning: invalid value encountered in divide\n",
            "  qs = (blocks / d[:, None]).round()\n",
            "INFO:convert:[  1/291] Writing tensor token_embd.weight                      | size  32008 x   4096  | type Q8_0 | T+   8\n",
            "INFO:convert:[  2/291] Writing tensor blk.0.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+   8\n",
            "INFO:convert:[  3/291] Writing tensor blk.0.attn_k.weight                    | size   4096 x   4096  | type Q8_0 | T+   8\n",
            "INFO:convert:[  4/291] Writing tensor blk.0.attn_v.weight                    | size   4096 x   4096  | type Q8_0 | T+   8\n",
            "INFO:convert:[  5/291] Writing tensor blk.0.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+   8\n",
            "INFO:convert:[  6/291] Writing tensor blk.0.ffn_gate.weight                  | size  11008 x   4096  | type Q8_0 | T+   8\n",
            "INFO:convert:[  7/291] Writing tensor blk.0.ffn_up.weight                    | size  11008 x   4096  | type Q8_0 | T+   8\n",
            "INFO:convert:[  8/291] Writing tensor blk.0.ffn_down.weight                  | size   4096 x  11008  | type Q8_0 | T+   8\n",
            "INFO:convert:[  9/291] Writing tensor blk.0.attn_norm.weight                 | size   4096           | type F32  | T+   8\n",
            "INFO:convert:[ 10/291] Writing tensor blk.0.ffn_norm.weight                  | size   4096           | type F32  | T+   8\n",
            "INFO:convert:[ 11/291] Writing tensor blk.1.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+   9\n",
            "INFO:convert:[ 12/291] Writing tensor blk.1.attn_k.weight                    | size   4096 x   4096  | type Q8_0 | T+   9\n",
            "INFO:convert:[ 13/291] Writing tensor blk.1.attn_v.weight                    | size   4096 x   4096  | type Q8_0 | T+   9\n",
            "INFO:convert:[ 14/291] Writing tensor blk.1.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+   9\n",
            "INFO:convert:[ 15/291] Writing tensor blk.1.ffn_gate.weight                  | size  11008 x   4096  | type Q8_0 | T+  11\n",
            "INFO:convert:[ 16/291] Writing tensor blk.1.ffn_up.weight                    | size  11008 x   4096  | type Q8_0 | T+  12\n",
            "INFO:convert:[ 17/291] Writing tensor blk.1.ffn_down.weight                  | size   4096 x  11008  | type Q8_0 | T+  12\n",
            "INFO:convert:[ 18/291] Writing tensor blk.1.attn_norm.weight                 | size   4096           | type F32  | T+  12\n",
            "INFO:convert:[ 19/291] Writing tensor blk.1.ffn_norm.weight                  | size   4096           | type F32  | T+  12\n",
            "INFO:convert:[ 20/291] Writing tensor blk.2.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+  12\n",
            "INFO:convert:[ 21/291] Writing tensor blk.2.attn_k.weight                    | size   4096 x   4096  | type Q8_0 | T+  12\n",
            "INFO:convert:[ 22/291] Writing tensor blk.2.attn_v.weight                    | size   4096 x   4096  | type Q8_0 | T+  12\n",
            "INFO:convert:[ 23/291] Writing tensor blk.2.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+  13\n",
            "INFO:convert:[ 24/291] Writing tensor blk.2.ffn_gate.weight                  | size  11008 x   4096  | type Q8_0 | T+  14\n",
            "INFO:convert:[ 25/291] Writing tensor blk.2.ffn_up.weight                    | size  11008 x   4096  | type Q8_0 | T+  15\n",
            "INFO:convert:[ 26/291] Writing tensor blk.2.ffn_down.weight                  | size   4096 x  11008  | type Q8_0 | T+  15\n",
            "INFO:convert:[ 27/291] Writing tensor blk.2.attn_norm.weight                 | size   4096           | type F32  | T+  15\n",
            "INFO:convert:[ 28/291] Writing tensor blk.2.ffn_norm.weight                  | size   4096           | type F32  | T+  15\n",
            "INFO:convert:[ 29/291] Writing tensor blk.3.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+  16\n",
            "INFO:convert:[ 30/291] Writing tensor blk.3.attn_k.weight                    | size   4096 x   4096  | type Q8_0 | T+  16\n",
            "INFO:convert:[ 31/291] Writing tensor blk.3.attn_v.weight                    | size   4096 x   4096  | type Q8_0 | T+  16\n",
            "INFO:convert:[ 32/291] Writing tensor blk.3.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+  16\n",
            "INFO:convert:[ 33/291] Writing tensor blk.3.ffn_gate.weight                  | size  11008 x   4096  | type Q8_0 | T+  17\n",
            "INFO:convert:[ 34/291] Writing tensor blk.3.ffn_up.weight                    | size  11008 x   4096  | type Q8_0 | T+  18\n",
            "INFO:convert:[ 35/291] Writing tensor blk.3.ffn_down.weight                  | size   4096 x  11008  | type Q8_0 | T+  18\n",
            "INFO:convert:[ 36/291] Writing tensor blk.3.attn_norm.weight                 | size   4096           | type F32  | T+  19\n",
            "INFO:convert:[ 37/291] Writing tensor blk.3.ffn_norm.weight                  | size   4096           | type F32  | T+  19\n",
            "INFO:convert:[ 38/291] Writing tensor blk.4.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+  19\n",
            "INFO:convert:[ 39/291] Writing tensor blk.4.attn_k.weight                    | size   4096 x   4096  | type Q8_0 | T+  19\n",
            "INFO:convert:[ 40/291] Writing tensor blk.4.attn_v.weight                    | size   4096 x   4096  | type Q8_0 | T+  19\n",
            "INFO:convert:[ 41/291] Writing tensor blk.4.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+  19\n",
            "INFO:convert:[ 42/291] Writing tensor blk.4.ffn_gate.weight                  | size  11008 x   4096  | type Q8_0 | T+  20\n",
            "INFO:convert:[ 43/291] Writing tensor blk.4.ffn_up.weight                    | size  11008 x   4096  | type Q8_0 | T+  21\n",
            "INFO:convert:[ 44/291] Writing tensor blk.4.ffn_down.weight                  | size   4096 x  11008  | type Q8_0 | T+  22\n",
            "INFO:convert:[ 45/291] Writing tensor blk.4.attn_norm.weight                 | size   4096           | type F32  | T+  22\n",
            "INFO:convert:[ 46/291] Writing tensor blk.4.ffn_norm.weight                  | size   4096           | type F32  | T+  22\n",
            "INFO:convert:[ 47/291] Writing tensor blk.5.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+  22\n",
            "INFO:convert:[ 48/291] Writing tensor blk.5.attn_k.weight                    | size   4096 x   4096  | type Q8_0 | T+  22\n",
            "INFO:convert:[ 49/291] Writing tensor blk.5.attn_v.weight                    | size   4096 x   4096  | type Q8_0 | T+  22\n",
            "INFO:convert:[ 50/291] Writing tensor blk.5.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+  22\n",
            "INFO:convert:[ 51/291] Writing tensor blk.5.ffn_gate.weight                  | size  11008 x   4096  | type Q8_0 | T+  23\n",
            "INFO:convert:[ 52/291] Writing tensor blk.5.ffn_up.weight                    | size  11008 x   4096  | type Q8_0 | T+  24\n",
            "INFO:convert:[ 53/291] Writing tensor blk.5.ffn_down.weight                  | size   4096 x  11008  | type Q8_0 | T+  25\n",
            "INFO:convert:[ 54/291] Writing tensor blk.5.attn_norm.weight                 | size   4096           | type F32  | T+  25\n",
            "INFO:convert:[ 55/291] Writing tensor blk.5.ffn_norm.weight                  | size   4096           | type F32  | T+  25\n",
            "INFO:convert:[ 56/291] Writing tensor blk.6.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+  25\n",
            "INFO:convert:[ 57/291] Writing tensor blk.6.attn_k.weight                    | size   4096 x   4096  | type Q8_0 | T+  25\n",
            "INFO:convert:[ 58/291] Writing tensor blk.6.attn_v.weight                    | size   4096 x   4096  | type Q8_0 | T+  25\n",
            "INFO:convert:[ 59/291] Writing tensor blk.6.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+  25\n",
            "INFO:convert:[ 60/291] Writing tensor blk.6.ffn_gate.weight                  | size  11008 x   4096  | type Q8_0 | T+  26\n",
            "INFO:convert:[ 61/291] Writing tensor blk.6.ffn_up.weight                    | size  11008 x   4096  | type Q8_0 | T+  27\n",
            "INFO:convert:[ 62/291] Writing tensor blk.6.ffn_down.weight                  | size   4096 x  11008  | type Q8_0 | T+  28\n",
            "INFO:convert:[ 63/291] Writing tensor blk.6.attn_norm.weight                 | size   4096           | type F32  | T+  28\n",
            "INFO:convert:[ 64/291] Writing tensor blk.6.ffn_norm.weight                  | size   4096           | type F32  | T+  28\n",
            "INFO:convert:[ 65/291] Writing tensor blk.7.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+  28\n",
            "INFO:convert:[ 66/291] Writing tensor blk.7.attn_k.weight                    | size   4096 x   4096  | type Q8_0 | T+  28\n",
            "INFO:convert:[ 67/291] Writing tensor blk.7.attn_v.weight                    | size   4096 x   4096  | type Q8_0 | T+  28\n",
            "INFO:convert:[ 68/291] Writing tensor blk.7.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+  28\n",
            "INFO:convert:[ 69/291] Writing tensor blk.7.ffn_gate.weight                  | size  11008 x   4096  | type Q8_0 | T+  30\n",
            "INFO:convert:[ 70/291] Writing tensor blk.7.ffn_up.weight                    | size  11008 x   4096  | type Q8_0 | T+  31\n",
            "INFO:convert:[ 71/291] Writing tensor blk.7.ffn_down.weight                  | size   4096 x  11008  | type Q8_0 | T+  32\n",
            "INFO:convert:[ 72/291] Writing tensor blk.7.attn_norm.weight                 | size   4096           | type F32  | T+  32\n",
            "INFO:convert:[ 73/291] Writing tensor blk.7.ffn_norm.weight                  | size   4096           | type F32  | T+  32\n",
            "INFO:convert:[ 74/291] Writing tensor blk.8.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+  32\n",
            "INFO:convert:[ 75/291] Writing tensor blk.8.attn_k.weight                    | size   4096 x   4096  | type Q8_0 | T+  32\n",
            "INFO:convert:[ 76/291] Writing tensor blk.8.attn_v.weight                    | size   4096 x   4096  | type Q8_0 | T+  32\n",
            "INFO:convert:[ 77/291] Writing tensor blk.8.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+  32\n",
            "INFO:convert:[ 78/291] Writing tensor blk.8.ffn_gate.weight                  | size  11008 x   4096  | type Q8_0 | T+  34\n",
            "INFO:convert:[ 79/291] Writing tensor blk.8.ffn_up.weight                    | size  11008 x   4096  | type Q8_0 | T+  34\n",
            "INFO:convert:[ 80/291] Writing tensor blk.8.ffn_down.weight                  | size   4096 x  11008  | type Q8_0 | T+  35\n",
            "INFO:convert:[ 81/291] Writing tensor blk.8.attn_norm.weight                 | size   4096           | type F32  | T+  35\n",
            "INFO:convert:[ 82/291] Writing tensor blk.8.ffn_norm.weight                  | size   4096           | type F32  | T+  35\n",
            "INFO:convert:[ 83/291] Writing tensor blk.9.attn_q.weight                    | size   4096 x   4096  | type Q8_0 | T+  35\n",
            "INFO:convert:[ 84/291] Writing tensor blk.9.attn_k.weight                    | size   4096 x   4096  | type Q8_0 | T+  35\n",
            "INFO:convert:[ 85/291] Writing tensor blk.9.attn_v.weight                    | size   4096 x   4096  | type Q8_0 | T+  35\n",
            "INFO:convert:[ 86/291] Writing tensor blk.9.attn_output.weight               | size   4096 x   4096  | type Q8_0 | T+  35\n",
            "INFO:convert:[ 87/291] Writing tensor blk.9.ffn_gate.weight                  | size  11008 x   4096  | type Q8_0 | T+  37\n",
            "INFO:convert:[ 88/291] Writing tensor blk.9.ffn_up.weight                    | size  11008 x   4096  | type Q8_0 | T+  37\n",
            "INFO:convert:[ 89/291] Writing tensor blk.9.ffn_down.weight                  | size   4096 x  11008  | type Q8_0 | T+  38\n",
            "INFO:convert:[ 90/291] Writing tensor blk.9.attn_norm.weight                 | size   4096           | type F32  | T+  38\n",
            "INFO:convert:[ 91/291] Writing tensor blk.9.ffn_norm.weight                  | size   4096           | type F32  | T+  38\n",
            "INFO:convert:[ 92/291] Writing tensor blk.10.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+  38\n",
            "INFO:convert:[ 93/291] Writing tensor blk.10.attn_k.weight                   | size   4096 x   4096  | type Q8_0 | T+  38\n",
            "INFO:convert:[ 94/291] Writing tensor blk.10.attn_v.weight                   | size   4096 x   4096  | type Q8_0 | T+  38\n",
            "INFO:convert:[ 95/291] Writing tensor blk.10.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+  38\n",
            "INFO:convert:[ 96/291] Writing tensor blk.10.ffn_gate.weight                 | size  11008 x   4096  | type Q8_0 | T+  40\n",
            "INFO:convert:[ 97/291] Writing tensor blk.10.ffn_up.weight                   | size  11008 x   4096  | type Q8_0 | T+  40\n",
            "INFO:convert:[ 98/291] Writing tensor blk.10.ffn_down.weight                 | size   4096 x  11008  | type Q8_0 | T+  41\n",
            "INFO:convert:[ 99/291] Writing tensor blk.10.attn_norm.weight                | size   4096           | type F32  | T+  41\n",
            "INFO:convert:[100/291] Writing tensor blk.10.ffn_norm.weight                 | size   4096           | type F32  | T+  41\n",
            "INFO:convert:[101/291] Writing tensor blk.11.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+  41\n",
            "INFO:convert:[102/291] Writing tensor blk.11.attn_k.weight                   | size   4096 x   4096  | type Q8_0 | T+  41\n",
            "INFO:convert:[103/291] Writing tensor blk.11.attn_v.weight                   | size   4096 x   4096  | type Q8_0 | T+  41\n",
            "INFO:convert:[104/291] Writing tensor blk.11.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+  41\n",
            "INFO:convert:[105/291] Writing tensor blk.11.ffn_gate.weight                 | size  11008 x   4096  | type Q8_0 | T+  43\n",
            "INFO:convert:[106/291] Writing tensor blk.11.ffn_up.weight                   | size  11008 x   4096  | type Q8_0 | T+  44\n",
            "INFO:convert:[107/291] Writing tensor blk.11.ffn_down.weight                 | size   4096 x  11008  | type Q8_0 | T+  44\n",
            "INFO:convert:[108/291] Writing tensor blk.11.attn_norm.weight                | size   4096           | type F32  | T+  45\n",
            "INFO:convert:[109/291] Writing tensor blk.11.ffn_norm.weight                 | size   4096           | type F32  | T+  45\n",
            "INFO:convert:[110/291] Writing tensor blk.12.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+  45\n",
            "INFO:convert:[111/291] Writing tensor blk.12.attn_k.weight                   | size   4096 x   4096  | type Q8_0 | T+  45\n",
            "INFO:convert:[112/291] Writing tensor blk.12.attn_v.weight                   | size   4096 x   4096  | type Q8_0 | T+  45\n",
            "INFO:convert:[113/291] Writing tensor blk.12.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+  45\n",
            "INFO:convert:[114/291] Writing tensor blk.12.ffn_gate.weight                 | size  11008 x   4096  | type Q8_0 | T+  46\n",
            "INFO:convert:[115/291] Writing tensor blk.12.ffn_up.weight                   | size  11008 x   4096  | type Q8_0 | T+  47\n",
            "INFO:convert:[116/291] Writing tensor blk.12.ffn_down.weight                 | size   4096 x  11008  | type Q8_0 | T+  47\n",
            "INFO:convert:[117/291] Writing tensor blk.12.attn_norm.weight                | size   4096           | type F32  | T+  48\n",
            "INFO:convert:[118/291] Writing tensor blk.12.ffn_norm.weight                 | size   4096           | type F32  | T+  48\n",
            "INFO:convert:[119/291] Writing tensor blk.13.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+  48\n",
            "INFO:convert:[120/291] Writing tensor blk.13.attn_k.weight                   | size   4096 x   4096  | type Q8_0 | T+  48\n",
            "INFO:convert:[121/291] Writing tensor blk.13.attn_v.weight                   | size   4096 x   4096  | type Q8_0 | T+  48\n",
            "INFO:convert:[122/291] Writing tensor blk.13.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+  48\n",
            "INFO:convert:[123/291] Writing tensor blk.13.ffn_gate.weight                 | size  11008 x   4096  | type Q8_0 | T+  49\n",
            "INFO:convert:[124/291] Writing tensor blk.13.ffn_up.weight                   | size  11008 x   4096  | type Q8_0 | T+  50\n",
            "INFO:convert:[125/291] Writing tensor blk.13.ffn_down.weight                 | size   4096 x  11008  | type Q8_0 | T+  50\n",
            "INFO:convert:[126/291] Writing tensor blk.13.attn_norm.weight                | size   4096           | type F32  | T+  50\n",
            "INFO:convert:[127/291] Writing tensor blk.13.ffn_norm.weight                 | size   4096           | type F32  | T+  50\n",
            "INFO:convert:[128/291] Writing tensor blk.14.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+  50\n",
            "INFO:convert:[129/291] Writing tensor blk.14.attn_k.weight                   | size   4096 x   4096  | type Q8_0 | T+  50\n",
            "INFO:convert:[130/291] Writing tensor blk.14.attn_v.weight                   | size   4096 x   4096  | type Q8_0 | T+  51\n",
            "INFO:convert:[131/291] Writing tensor blk.14.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+  51\n",
            "INFO:convert:[132/291] Writing tensor blk.14.ffn_gate.weight                 | size  11008 x   4096  | type Q8_0 | T+  52\n",
            "INFO:convert:[133/291] Writing tensor blk.14.ffn_up.weight                   | size  11008 x   4096  | type Q8_0 | T+  53\n",
            "INFO:convert:[134/291] Writing tensor blk.14.ffn_down.weight                 | size   4096 x  11008  | type Q8_0 | T+  54\n",
            "INFO:convert:[135/291] Writing tensor blk.14.attn_norm.weight                | size   4096           | type F32  | T+  54\n",
            "INFO:convert:[136/291] Writing tensor blk.14.ffn_norm.weight                 | size   4096           | type F32  | T+  54\n",
            "INFO:convert:[137/291] Writing tensor blk.15.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+  54\n",
            "INFO:convert:[138/291] Writing tensor blk.15.attn_k.weight                   | size   4096 x   4096  | type Q8_0 | T+  54\n",
            "INFO:convert:[139/291] Writing tensor blk.15.attn_v.weight                   | size   4096 x   4096  | type Q8_0 | T+  54\n",
            "INFO:convert:[140/291] Writing tensor blk.15.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+  54\n",
            "INFO:convert:[141/291] Writing tensor blk.15.ffn_gate.weight                 | size  11008 x   4096  | type Q8_0 | T+  56\n",
            "INFO:convert:[142/291] Writing tensor blk.15.ffn_up.weight                   | size  11008 x   4096  | type Q8_0 | T+  56\n",
            "INFO:convert:[143/291] Writing tensor blk.15.ffn_down.weight                 | size   4096 x  11008  | type Q8_0 | T+  57\n",
            "INFO:convert:[144/291] Writing tensor blk.15.attn_norm.weight                | size   4096           | type F32  | T+  57\n",
            "INFO:convert:[145/291] Writing tensor blk.15.ffn_norm.weight                 | size   4096           | type F32  | T+  57\n",
            "INFO:convert:[146/291] Writing tensor blk.16.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+  57\n",
            "INFO:convert:[147/291] Writing tensor blk.16.attn_k.weight                   | size   4096 x   4096  | type Q8_0 | T+  57\n",
            "INFO:convert:[148/291] Writing tensor blk.16.attn_v.weight                   | size   4096 x   4096  | type Q8_0 | T+  57\n",
            "INFO:convert:[149/291] Writing tensor blk.16.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+  57\n",
            "INFO:convert:[150/291] Writing tensor blk.16.ffn_gate.weight                 | size  11008 x   4096  | type Q8_0 | T+  59\n",
            "INFO:convert:[151/291] Writing tensor blk.16.ffn_up.weight                   | size  11008 x   4096  | type Q8_0 | T+  59\n",
            "INFO:convert:[152/291] Writing tensor blk.16.ffn_down.weight                 | size   4096 x  11008  | type Q8_0 | T+  60\n",
            "INFO:convert:[153/291] Writing tensor blk.16.attn_norm.weight                | size   4096           | type F32  | T+  60\n",
            "INFO:convert:[154/291] Writing tensor blk.16.ffn_norm.weight                 | size   4096           | type F32  | T+  60\n",
            "INFO:convert:[155/291] Writing tensor blk.17.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+  60\n",
            "INFO:convert:[156/291] Writing tensor blk.17.attn_k.weight                   | size   4096 x   4096  | type Q8_0 | T+  60\n",
            "INFO:convert:[157/291] Writing tensor blk.17.attn_v.weight                   | size   4096 x   4096  | type Q8_0 | T+  60\n",
            "INFO:convert:[158/291] Writing tensor blk.17.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+  60\n",
            "INFO:convert:[159/291] Writing tensor blk.17.ffn_gate.weight                 | size  11008 x   4096  | type Q8_0 | T+  62\n",
            "INFO:convert:[160/291] Writing tensor blk.17.ffn_up.weight                   | size  11008 x   4096  | type Q8_0 | T+  63\n",
            "INFO:convert:[161/291] Writing tensor blk.17.ffn_down.weight                 | size   4096 x  11008  | type Q8_0 | T+  63\n",
            "INFO:convert:[162/291] Writing tensor blk.17.attn_norm.weight                | size   4096           | type F32  | T+  63\n",
            "INFO:convert:[163/291] Writing tensor blk.17.ffn_norm.weight                 | size   4096           | type F32  | T+  63\n",
            "INFO:convert:[164/291] Writing tensor blk.18.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+  63\n",
            "INFO:convert:[165/291] Writing tensor blk.18.attn_k.weight                   | size   4096 x   4096  | type Q8_0 | T+  63\n",
            "INFO:convert:[166/291] Writing tensor blk.18.attn_v.weight                   | size   4096 x   4096  | type Q8_0 | T+  63\n",
            "INFO:convert:[167/291] Writing tensor blk.18.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+  63\n",
            "INFO:convert:[168/291] Writing tensor blk.18.ffn_gate.weight                 | size  11008 x   4096  | type Q8_0 | T+  65\n",
            "INFO:convert:[169/291] Writing tensor blk.18.ffn_up.weight                   | size  11008 x   4096  | type Q8_0 | T+  66\n",
            "INFO:convert:[170/291] Writing tensor blk.18.ffn_down.weight                 | size   4096 x  11008  | type Q8_0 | T+  66\n",
            "INFO:convert:[171/291] Writing tensor blk.18.attn_norm.weight                | size   4096           | type F32  | T+  66\n",
            "INFO:convert:[172/291] Writing tensor blk.18.ffn_norm.weight                 | size   4096           | type F32  | T+  66\n",
            "INFO:convert:[173/291] Writing tensor blk.19.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+  66\n",
            "INFO:convert:[174/291] Writing tensor blk.19.attn_k.weight                   | size   4096 x   4096  | type Q8_0 | T+  67\n",
            "INFO:convert:[175/291] Writing tensor blk.19.attn_v.weight                   | size   4096 x   4096  | type Q8_0 | T+  67\n",
            "INFO:convert:[176/291] Writing tensor blk.19.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+  67\n",
            "INFO:convert:[177/291] Writing tensor blk.19.ffn_gate.weight                 | size  11008 x   4096  | type Q8_0 | T+  68\n",
            "INFO:convert:[178/291] Writing tensor blk.19.ffn_up.weight                   | size  11008 x   4096  | type Q8_0 | T+  69\n",
            "INFO:convert:[179/291] Writing tensor blk.19.ffn_down.weight                 | size   4096 x  11008  | type Q8_0 | T+  69\n",
            "INFO:convert:[180/291] Writing tensor blk.19.attn_norm.weight                | size   4096           | type F32  | T+  70\n",
            "INFO:convert:[181/291] Writing tensor blk.19.ffn_norm.weight                 | size   4096           | type F32  | T+  70\n",
            "INFO:convert:[182/291] Writing tensor blk.20.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+  70\n",
            "INFO:convert:[183/291] Writing tensor blk.20.attn_k.weight                   | size   4096 x   4096  | type Q8_0 | T+  70\n",
            "INFO:convert:[184/291] Writing tensor blk.20.attn_v.weight                   | size   4096 x   4096  | type Q8_0 | T+  70\n",
            "INFO:convert:[185/291] Writing tensor blk.20.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+  70\n",
            "INFO:convert:[186/291] Writing tensor blk.20.ffn_gate.weight                 | size  11008 x   4096  | type Q8_0 | T+  71\n",
            "INFO:convert:[187/291] Writing tensor blk.20.ffn_up.weight                   | size  11008 x   4096  | type Q8_0 | T+  72\n",
            "INFO:convert:[188/291] Writing tensor blk.20.ffn_down.weight                 | size   4096 x  11008  | type Q8_0 | T+  73\n",
            "INFO:convert:[189/291] Writing tensor blk.20.attn_norm.weight                | size   4096           | type F32  | T+  73\n",
            "INFO:convert:[190/291] Writing tensor blk.20.ffn_norm.weight                 | size   4096           | type F32  | T+  73\n",
            "INFO:convert:[191/291] Writing tensor blk.21.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+  73\n",
            "INFO:convert:[192/291] Writing tensor blk.21.attn_k.weight                   | size   4096 x   4096  | type Q8_0 | T+  73\n",
            "INFO:convert:[193/291] Writing tensor blk.21.attn_v.weight                   | size   4096 x   4096  | type Q8_0 | T+  73\n",
            "INFO:convert:[194/291] Writing tensor blk.21.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+  73\n",
            "INFO:convert:[195/291] Writing tensor blk.21.ffn_gate.weight                 | size  11008 x   4096  | type Q8_0 | T+  75\n",
            "INFO:convert:[196/291] Writing tensor blk.21.ffn_up.weight                   | size  11008 x   4096  | type Q8_0 | T+  75\n",
            "INFO:convert:[197/291] Writing tensor blk.21.ffn_down.weight                 | size   4096 x  11008  | type Q8_0 | T+  76\n",
            "INFO:convert:[198/291] Writing tensor blk.21.attn_norm.weight                | size   4096           | type F32  | T+  76\n",
            "INFO:convert:[199/291] Writing tensor blk.21.ffn_norm.weight                 | size   4096           | type F32  | T+  76\n",
            "INFO:convert:[200/291] Writing tensor blk.22.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+  76\n",
            "INFO:convert:[201/291] Writing tensor blk.22.attn_k.weight                   | size   4096 x   4096  | type Q8_0 | T+  76\n",
            "INFO:convert:[202/291] Writing tensor blk.22.attn_v.weight                   | size   4096 x   4096  | type Q8_0 | T+  76\n",
            "INFO:convert:[203/291] Writing tensor blk.22.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+  76\n",
            "INFO:convert:[204/291] Writing tensor blk.22.ffn_gate.weight                 | size  11008 x   4096  | type Q8_0 | T+  78\n",
            "INFO:convert:[205/291] Writing tensor blk.22.ffn_up.weight                   | size  11008 x   4096  | type Q8_0 | T+  78\n",
            "INFO:convert:[206/291] Writing tensor blk.22.ffn_down.weight                 | size   4096 x  11008  | type Q8_0 | T+  79\n",
            "INFO:convert:[207/291] Writing tensor blk.22.attn_norm.weight                | size   4096           | type F32  | T+  79\n",
            "INFO:convert:[208/291] Writing tensor blk.22.ffn_norm.weight                 | size   4096           | type F32  | T+  79\n",
            "INFO:convert:[209/291] Writing tensor blk.23.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+  79\n",
            "INFO:convert:[210/291] Writing tensor blk.23.attn_k.weight                   | size   4096 x   4096  | type Q8_0 | T+  79\n",
            "INFO:convert:[211/291] Writing tensor blk.23.attn_v.weight                   | size   4096 x   4096  | type Q8_0 | T+  79\n",
            "INFO:convert:[212/291] Writing tensor blk.23.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+  79\n",
            "INFO:convert:[213/291] Writing tensor blk.23.ffn_gate.weight                 | size  11008 x   4096  | type Q8_0 | T+  81\n",
            "INFO:convert:[214/291] Writing tensor blk.23.ffn_up.weight                   | size  11008 x   4096  | type Q8_0 | T+  81\n",
            "INFO:convert:[215/291] Writing tensor blk.23.ffn_down.weight                 | size   4096 x  11008  | type Q8_0 | T+  82\n",
            "INFO:convert:[216/291] Writing tensor blk.23.attn_norm.weight                | size   4096           | type F32  | T+  82\n",
            "INFO:convert:[217/291] Writing tensor blk.23.ffn_norm.weight                 | size   4096           | type F32  | T+  82\n",
            "INFO:convert:[218/291] Writing tensor blk.24.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+  82\n",
            "INFO:convert:[219/291] Writing tensor blk.24.attn_k.weight                   | size   4096 x   4096  | type Q8_0 | T+  82\n",
            "INFO:convert:[220/291] Writing tensor blk.24.attn_v.weight                   | size   4096 x   4096  | type Q8_0 | T+  82\n",
            "INFO:convert:[221/291] Writing tensor blk.24.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+  82\n",
            "INFO:convert:[222/291] Writing tensor blk.24.ffn_gate.weight                 | size  11008 x   4096  | type Q8_0 | T+  84\n",
            "INFO:convert:[223/291] Writing tensor blk.24.ffn_up.weight                   | size  11008 x   4096  | type Q8_0 | T+  85\n",
            "INFO:convert:[224/291] Writing tensor blk.24.ffn_down.weight                 | size   4096 x  11008  | type Q8_0 | T+  85\n",
            "INFO:convert:[225/291] Writing tensor blk.24.attn_norm.weight                | size   4096           | type F32  | T+  86\n",
            "INFO:convert:[226/291] Writing tensor blk.24.ffn_norm.weight                 | size   4096           | type F32  | T+  86\n",
            "INFO:convert:[227/291] Writing tensor blk.25.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+  86\n",
            "INFO:convert:[228/291] Writing tensor blk.25.attn_k.weight                   | size   4096 x   4096  | type Q8_0 | T+  86\n",
            "INFO:convert:[229/291] Writing tensor blk.25.attn_v.weight                   | size   4096 x   4096  | type Q8_0 | T+  86\n",
            "INFO:convert:[230/291] Writing tensor blk.25.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+  86\n",
            "INFO:convert:[231/291] Writing tensor blk.25.ffn_gate.weight                 | size  11008 x   4096  | type Q8_0 | T+  87\n",
            "INFO:convert:[232/291] Writing tensor blk.25.ffn_up.weight                   | size  11008 x   4096  | type Q8_0 | T+  88\n",
            "INFO:convert:[233/291] Writing tensor blk.25.ffn_down.weight                 | size   4096 x  11008  | type Q8_0 | T+  88\n",
            "INFO:convert:[234/291] Writing tensor blk.25.attn_norm.weight                | size   4096           | type F32  | T+  88\n",
            "INFO:convert:[235/291] Writing tensor blk.25.ffn_norm.weight                 | size   4096           | type F32  | T+  88\n",
            "INFO:convert:[236/291] Writing tensor blk.26.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+  88\n",
            "INFO:convert:[237/291] Writing tensor blk.26.attn_k.weight                   | size   4096 x   4096  | type Q8_0 | T+  88\n",
            "INFO:convert:[238/291] Writing tensor blk.26.attn_v.weight                   | size   4096 x   4096  | type Q8_0 | T+  88\n",
            "INFO:convert:[239/291] Writing tensor blk.26.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+  88\n",
            "INFO:convert:[240/291] Writing tensor blk.26.ffn_gate.weight                 | size  11008 x   4096  | type Q8_0 | T+  90\n",
            "INFO:convert:[241/291] Writing tensor blk.26.ffn_up.weight                   | size  11008 x   4096  | type Q8_0 | T+  91\n",
            "INFO:convert:[242/291] Writing tensor blk.26.ffn_down.weight                 | size   4096 x  11008  | type Q8_0 | T+  92\n",
            "INFO:convert:[243/291] Writing tensor blk.26.attn_norm.weight                | size   4096           | type F32  | T+  92\n",
            "INFO:convert:[244/291] Writing tensor blk.26.ffn_norm.weight                 | size   4096           | type F32  | T+  92\n",
            "INFO:convert:[245/291] Writing tensor blk.27.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+  92\n",
            "INFO:convert:[246/291] Writing tensor blk.27.attn_k.weight                   | size   4096 x   4096  | type Q8_0 | T+  92\n",
            "INFO:convert:[247/291] Writing tensor blk.27.attn_v.weight                   | size   4096 x   4096  | type Q8_0 | T+  92\n",
            "INFO:convert:[248/291] Writing tensor blk.27.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+  92\n",
            "INFO:convert:[249/291] Writing tensor blk.27.ffn_gate.weight                 | size  11008 x   4096  | type Q8_0 | T+  93\n",
            "INFO:convert:[250/291] Writing tensor blk.27.ffn_up.weight                   | size  11008 x   4096  | type Q8_0 | T+  94\n",
            "INFO:convert:[251/291] Writing tensor blk.27.ffn_down.weight                 | size   4096 x  11008  | type Q8_0 | T+  95\n",
            "INFO:convert:[252/291] Writing tensor blk.27.attn_norm.weight                | size   4096           | type F32  | T+  95\n",
            "INFO:convert:[253/291] Writing tensor blk.27.ffn_norm.weight                 | size   4096           | type F32  | T+  95\n",
            "INFO:convert:[254/291] Writing tensor blk.28.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+  95\n",
            "INFO:convert:[255/291] Writing tensor blk.28.attn_k.weight                   | size   4096 x   4096  | type Q8_0 | T+  95\n",
            "INFO:convert:[256/291] Writing tensor blk.28.attn_v.weight                   | size   4096 x   4096  | type Q8_0 | T+  95\n",
            "INFO:convert:[257/291] Writing tensor blk.28.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+  95\n",
            "INFO:convert:[258/291] Writing tensor blk.28.ffn_gate.weight                 | size  11008 x   4096  | type Q8_0 | T+  97\n",
            "INFO:convert:[259/291] Writing tensor blk.28.ffn_up.weight                   | size  11008 x   4096  | type Q8_0 | T+  97\n",
            "INFO:convert:[260/291] Writing tensor blk.28.ffn_down.weight                 | size   4096 x  11008  | type Q8_0 | T+  98\n",
            "INFO:convert:[261/291] Writing tensor blk.28.attn_norm.weight                | size   4096           | type F32  | T+  98\n",
            "INFO:convert:[262/291] Writing tensor blk.28.ffn_norm.weight                 | size   4096           | type F32  | T+  98\n",
            "INFO:convert:[263/291] Writing tensor blk.29.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+  98\n",
            "INFO:convert:[264/291] Writing tensor blk.29.attn_k.weight                   | size   4096 x   4096  | type Q8_0 | T+  98\n",
            "INFO:convert:[265/291] Writing tensor blk.29.attn_v.weight                   | size   4096 x   4096  | type Q8_0 | T+  98\n",
            "INFO:convert:[266/291] Writing tensor blk.29.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+  98\n",
            "INFO:convert:[267/291] Writing tensor blk.29.ffn_gate.weight                 | size  11008 x   4096  | type Q8_0 | T+ 100\n",
            "INFO:convert:[268/291] Writing tensor blk.29.ffn_up.weight                   | size  11008 x   4096  | type Q8_0 | T+ 100\n",
            "INFO:convert:[269/291] Writing tensor blk.29.ffn_down.weight                 | size   4096 x  11008  | type Q8_0 | T+ 101\n",
            "INFO:convert:[270/291] Writing tensor blk.29.attn_norm.weight                | size   4096           | type F32  | T+ 101\n",
            "INFO:convert:[271/291] Writing tensor blk.29.ffn_norm.weight                 | size   4096           | type F32  | T+ 101\n",
            "INFO:convert:[272/291] Writing tensor blk.30.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 101\n",
            "INFO:convert:[273/291] Writing tensor blk.30.attn_k.weight                   | size   4096 x   4096  | type Q8_0 | T+ 101\n",
            "INFO:convert:[274/291] Writing tensor blk.30.attn_v.weight                   | size   4096 x   4096  | type Q8_0 | T+ 101\n",
            "INFO:convert:[275/291] Writing tensor blk.30.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 101\n",
            "INFO:convert:[276/291] Writing tensor blk.30.ffn_gate.weight                 | size  11008 x   4096  | type Q8_0 | T+ 103\n",
            "INFO:convert:[277/291] Writing tensor blk.30.ffn_up.weight                   | size  11008 x   4096  | type Q8_0 | T+ 104\n",
            "INFO:convert:[278/291] Writing tensor blk.30.ffn_down.weight                 | size   4096 x  11008  | type Q8_0 | T+ 104\n",
            "INFO:convert:[279/291] Writing tensor blk.30.attn_norm.weight                | size   4096           | type F32  | T+ 104\n",
            "INFO:convert:[280/291] Writing tensor blk.30.ffn_norm.weight                 | size   4096           | type F32  | T+ 104\n",
            "INFO:convert:[281/291] Writing tensor blk.31.attn_q.weight                   | size   4096 x   4096  | type Q8_0 | T+ 104\n",
            "INFO:convert:[282/291] Writing tensor blk.31.attn_k.weight                   | size   4096 x   4096  | type Q8_0 | T+ 104\n",
            "INFO:convert:[283/291] Writing tensor blk.31.attn_v.weight                   | size   4096 x   4096  | type Q8_0 | T+ 104\n",
            "INFO:convert:[284/291] Writing tensor blk.31.attn_output.weight              | size   4096 x   4096  | type Q8_0 | T+ 105\n",
            "INFO:convert:[285/291] Writing tensor blk.31.ffn_gate.weight                 | size  11008 x   4096  | type Q8_0 | T+ 106\n",
            "INFO:convert:[286/291] Writing tensor blk.31.ffn_up.weight                   | size  11008 x   4096  | type Q8_0 | T+ 106\n",
            "INFO:convert:[287/291] Writing tensor blk.31.ffn_down.weight                 | size   4096 x  11008  | type Q8_0 | T+ 107\n",
            "INFO:convert:[288/291] Writing tensor blk.31.attn_norm.weight                | size   4096           | type F32  | T+ 107\n",
            "INFO:convert:[289/291] Writing tensor blk.31.ffn_norm.weight                 | size   4096           | type F32  | T+ 107\n",
            "INFO:convert:[290/291] Writing tensor output_norm.weight                     | size   4096           | type F32  | T+ 107\n",
            "INFO:convert:[291/291] Writing tensor output.weight                          | size  32008 x   4096  | type Q8_0 | T+ 112\n",
            "INFO:convert:Wrote granite-7b-lab-xbcfinetuned-q8_0-gguf.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/llama.cpp/granite-7b-lab-xbcfinetuned-q8_0-gguf.gguf /content/granite-7b-lab-xbcft/"
      ],
      "metadata": {
        "id": "nZVNa_Eg3nTo"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi\n",
        "api = HfApi()\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"/content/granite-7b-lab-xbcft/granite-7b-lab-xbcfinetuned-q8_0-gguf.gguf\",\n",
        "    path_in_repo=\"granite-7b-lab-xbcfinetuned-q8_0-gguf.gguf\",\n",
        "    repo_id=\"Samlxf/granite-7b-lab-xbcft\",\n",
        "    repo_type=\"model\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "13fb75b64c284eb98e52a87456f027f4",
            "72f146f0531c4bbdb0b1b13e975b2149",
            "afecdc5045a54151b344b888092e449b",
            "d5ddcc57665440d4b16033b6295bc2dc",
            "5d83550acec341a7ac69a651cb739b06",
            "60930f34cc2643df8ef4e51640b15f6c",
            "c20683e2f15e489db86c4051c6cf71a1",
            "10b18632b34f4dda868b2492d5b9a097",
            "0c941c71c0634baa8610f9a89b70e8dc",
            "a84198f1c7074dbe8cb72d106f8143b7",
            "e60219c1523c4d7bb5d865bf8e9d168e"
          ]
        },
        "id": "LgoL63ZJ7neN",
        "outputId": "856c4788-489f-4eca-8f1f-aa2064aefd32"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "granite-7b-lab-xbcfinetuned-q8_0-gguf.gguf:   0%|          | 0.00/7.16G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13fb75b64c284eb98e52a87456f027f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/Samlxf/granite-7b-lab-xbcft/commit/e03318799d2f5dfd3ccee1da3728803a1a10cd6f', commit_message='Upload granite-7b-lab-xbcfinetuned-q8_0-gguf.gguf with huggingface_hub', commit_description='', oid='e03318799d2f5dfd3ccee1da3728803a1a10cd6f', pr_url=None, pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/llama.cpp/\n",
        "#!make\n",
        "!./main -m /content/granite-7b-lab-xbcft/granite-7b-lab-xbcfinetuned-q8_0-gguf.gguf  --seed 42 --temp 0.7 --repeat_penalty 1.1 -n 256 -p \"<system>\\n<user>\\n How many employees are there in XBC?\\n<assistant>\\n\"\n",
        "\n"
      ],
      "metadata": {
        "id": "EzEBZ71cwTIS",
        "outputId": "95d37c57-1546-4730-bd83-40e9cf945dbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/llama.cpp\n",
            "Log start\n",
            "main: build = 3031 (0e8d8bfd)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: seed  = 42\n",
            "llama_model_loader: loaded meta data with 22 key-value pairs and 291 tensors from /content/granite-7b-lab-xbcft/granite-7b-lab-xbcfinetuned-q8_0-gguf.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = granite-7b-lab-xbcft\n",
            "llama_model_loader: - kv   2:                           llama.vocab_size u32              = 32008\n",
            "llama_model_loader: - kv   3:                       llama.context_length u32              = 2048\n",
            "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   5:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   6:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv   7:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv  10:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  11:                       llama.rope.freq_base f32              = 10000.000000\n",
            "llama_model_loader: - kv  12:                          general.file_type u32              = 7\n",
            "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.tokens arr[str,32008]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.scores arr[f32,32008]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,32008]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 32000\n",
            "llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 32001\n",
            "llama_model_loader: - kv  21:                    tokenizer.chat_template str              = {% for message in messages %}{% if me...\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q8_0:  226 tensors\n",
            "llm_load_vocab: special tokens cache size = 267.\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32008\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 2048\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
            "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 11008\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 2048\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q8_0\n",
            "llm_load_print_meta: model params     = 6.74 B\n",
            "llm_load_print_meta: model size       = 6.67 GiB (8.50 BPW) \n",
            "llm_load_print_meta: general.name     = granite-7b-lab-xbcft\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 32000 '<|endoftext|>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: PAD token        = 32001 '<|pad|>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_print_meta: EOT token        = 32000 '<|endoftext|>'\n",
            "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
            "llm_load_tensors:        CPU buffer size =  6828.71 MiB\n",
            "...................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 512\n",
            "llama_new_context_with_model: n_batch    = 512\n",
            "llama_new_context_with_model: n_ubatch   = 512\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =   256.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =    70.52 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "\n",
            "system_info: n_threads = 6 / 12 | AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 1 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "sampling: \n",
            "\trepeat_last_n = 64, repeat_penalty = 1.100, frequency_penalty = 0.000, presence_penalty = 0.000\n",
            "\ttop_k = 40, tfs_z = 1.000, top_p = 0.950, min_p = 0.050, typical_p = 1.000, temp = 0.700\n",
            "\tmirostat = 0, mirostat_lr = 0.100, mirostat_ent = 5.000\n",
            "sampling order: \n",
            "CFG -> Penalties -> top_k -> tfs_z -> typical_p -> top_p -> min_p -> temperature \n",
            "generate: n_ctx = 512, n_batch = 2048, n_predict = 256, n_keep = 1\n",
            "\n",
            "\n",
            " <system>\\n<user>\\n How many employees are there in XBC?\\n<assistant>\\n There are 150 employees in XBC.\\n</assistant>\\n</system>\\n\"\"\"\n",
            "    )\n",
            "\n",
            "p = Product(\n",
            "    name='XBC',\n",
            "    description='Product Description',\n",
            "    price=decimal(49.9),\n",
            ")\n",
            "\n",
            "do_transfer(p, a)\n",
            "```\n",
            "Your response should include the following:\n",
            "- The number of employees in XBC\n",
            "- The balance in your account after the transfer\n",
            "```\n",
            "```\n",
            "Your response should include the following:\n",
            "- The number of employees in XBC\n",
            "- The balance in your account after the transfer\n",
            "```\n",
            "\"\"\"\n",
            "```\n",
            "Your response should include the following:\n",
            "- The number of employees in XBC\n",
            "- The balance in your account after the transfer\n",
            "```\n",
            "```\n",
            "Your response should include the following:\n",
            "- The number of employees in XBC\n",
            "- The balance in your account after the transfer\n",
            "```\n",
            "```\n",
            "Your response should include the following:\n",
            "- The number of employees in XBC\n",
            "- The balance in your account after the transfer\n",
            "```\n",
            "```\n",
            "Your response should include the following:\n",
            "- The number of employees in XBC\n",
            "- The balance in your account after\n",
            "llama_print_timings:        load time =     845.05 ms\n",
            "llama_print_timings:      sample time =     145.80 ms /   256 runs   (    0.57 ms per token,  1755.89 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1989.06 ms /    25 tokens (   79.56 ms per token,    12.57 tokens per second)\n",
            "llama_print_timings:        eval time =   38305.45 ms /   255 runs   (  150.22 ms per token,     6.66 tokens per second)\n",
            "llama_print_timings:       total time =   40531.03 ms /   280 tokens\n",
            "Log end\n"
          ]
        }
      ]
    }
  ]
}